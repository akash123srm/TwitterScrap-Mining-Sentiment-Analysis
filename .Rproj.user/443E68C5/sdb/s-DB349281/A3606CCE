{
    "collab_server" : "",
    "contents" : "library(\"twitteR\")\nlibrary(\"ROAuth\")\n\n\n#all this info is obtained for the Twitter developer account:\n\nkey <- \"NIAfLMyCaJytEMQmKm1tuzaK6\"\n\nsecret <- \"jisoQf0XGTnVPiBEIKWic113vXe4NFSIbno5inR35R70Iot1gB\"\n\n\naccess_token_secret <- \"sbpw4MQj2sH79o4wMrg8nSdqh0G5nSOgV9Slf7EH9ACqS\"\n\naccess_token <- \"2431900465-sDi7vsC4vXIgqw6cajvZlmIEdwiduOwZCGhdUTI\"\n\n\nlibrary(\"httr\")\n\n#This function wraps the OAuth authentication handshake functions \n#from the httr package for a twitteR session.Sets up the OAuth credentials for a twitteR session\n\n#Note we nead to have proper internet connection to run this function\n\nsetup_twitter_oauth(key, secret, access_token, access_token_secret)\n\n#Get the 1000 scraps with the keyword Udemy\n\ntweets_sachin <- searchTwitter(\"sachintendulkar\", n=1000, lang=\"en\")\n\n\nlibrary(\"tm\")\n\n\ntweet_list <- sapply(tweets_sachin, function(x) x$getText())\n\n# Create a corpus for the tweets\n\ncorpus_tweets <- Corpus(VectorSource(tweet_list))\n\n# Convert the text into the lowercase\n\ncorpus_tweets <- tm_map(corpus_tweets, tolower)\n\n# Remove punctuation\n\ncorpus_tweets <- tm_map(corpus_tweets, removePunctuation)\n\n# Remove white space\n\ncorpus_tweets <- tm_map(corpus_tweets, stripWhitespace)\n\n# Remove numbers\n\ncorpus_tweets <- tm_map(corpus_tweets, removeNumbers)\n\n# Remove stopwords\n\ncorpus_tweets <- tm_map(corpus_tweets, function(x)removeWords(x, stopwords()))\n\n\n# Converting text into plain text document\n\ncorpus_tweets <- tm_map(corpus_tweets, PlainTextDocument)\n\nlibrary(\"wordcloud\")\n\nlibrary(\"RColorBrewer\")\n\n? wordcloud\n\nw <- wordcloud(corpus_tweets, min.freq=5, scale=c(4,1), colors=brewer.pal(9,\"Dark2\"),\n          rot.per=0.5, random.color=F, max.word=50, random.order=F)\n\n# Saving the workcloud\n\nprint(w)\n\ndev.copy(png, filename='word_cloud_sachin.png')\n\ndev.off()\n\n#changing to a tdm\n\ncorpus_tweets_dtm <- TermDocumentMatrix(corpus_tweets)\n\nfindFreqTerms(corpus_tweets_dtm, lowfreq=10) # experiment with the lowfreq\n\ntdm <-removeSparseTerms(corpus_tweets_dtm, sparse=0.94) # experimet with sparse\n\ntdmscale <- scale(tdm)\n\ndist <- dist(tdmscale, method = \"euclidean\")\n\nfit <- hclust(dist)\n\nplot(fit)\n\n#-to calculate a certain number of groups\n\ncutree(fit, k=6)\n\n#-we can even color the 4 groups and plot them\n\n\ndendogram <- rect.hclust(fit, k=6, border=\"red\")\n\n# Saving the debdogram in the working directory\n\nprint(dendogram)\n\ndev.copy(png,filename=\"dendogram_sachin.png\")\n\ndev.off()\n\n\n\n\n\n",
    "created" : 1468411097036.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "22558423",
    "id" : "A3606CCE",
    "lastKnownWriteTime" : 1469029130,
    "last_content_update" : 1469193794949,
    "path" : "~/R/Twitter_Sentiment_Analysis/twitter_scrapping.R",
    "project_path" : "twitter_scrapping.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}